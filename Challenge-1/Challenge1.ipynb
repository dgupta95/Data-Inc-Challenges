{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Fire Incidents in New York"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a part of the challenges assigned by **The Data Incubator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The New York City Fire Department keeps a log of detailed information on incidents handled by FDNY units. In this challenge we will work with a dataset that contains a record of incidents handled by FDNY units from 2013-2017. Download the [FDNY data set](https://data.cityofnewyork.us/api/views/tm6d-hbzd/rows.csv?accessType=DOWNLOAD). Also take a look at the [dataset landing page](https://data.cityofnewyork.us/Public-Safety/Incidents-Responded-to-by-Fire-Companies/tm6d-hbzd) and find descriptions of column names [here](https://data.cityofnewyork.us/api/views/tm6d-hbzd/files/1434d09c-fbf8-4450-8b42-9fe0c3b85fb3?download=true&filename=OPEN_DATA_FIRE_INCIDENTS_FILE_DESCRIPTION.xls)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us load the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"Incidents_Responded_to_by_Fire_Companies.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a copy of the data to work on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us visualize it first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to clean up the data!\n",
    "\n",
    "Looks like not all the columns are not going to be useful for the exercise. I drop them here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['STANDPIPE_SYS_PRESENT_FLAG', 'AES_PRESENCE_DESC', 'DETECTOR_PRESENCE_DESC',\n",
    "                          'FIRE_SPREAD_DESC', 'STORY_FIRE_ORIGIN_COUNT', 'FIRE_ORIGIN_BELOW_GRADE_FLAG', 'FLOOR',\n",
    "                          'STREET_HIGHWAY', 'ACTION_TAKEN2_DESC', 'ACTION_TAKEN3_DESC', 'PROPERTY_USE_DESC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few columns have alphanumneric data. I'm only interested in the numeric data here; I can always look up what they mean later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['INCIDENT_TYPE_DESC']= data['INCIDENT_TYPE_DESC'].str.split(pat = \"-\").str[0] \n",
    "data['HIGHEST_LEVEL_DESC'] = data['HIGHEST_LEVEL_DESC'].str.split(pat = \"-\").str[0]\n",
    "data['ACTION_TAKEN1_DESC'] = data['ACTION_TAKEN1_DESC'].str.split(pat = \"-\").str[0]\n",
    "data['BOROUGH_DESC'] = data['BOROUGH_DESC'].str.split(pat = \"-\").str[0]\n",
    "data['ZIP_CODE'] = data['ZIP_CODE'].str.split(pat = \"-\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This probably is useful as numeric data. \n",
    "\n",
    "data['INCIDENT_TYPE_DESC'] = data['INCIDENT_TYPE_DESC'].str.split(pat = \"B\").str[0]\n",
    "data['INCIDENT_TYPE_DESC'] = data['INCIDENT_TYPE_DESC'].str.split(pat = \"A\").str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three columns that have `datetime` data. I use the `infer_datetime_format=True` option to speed up the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Datetime data\n",
    "\n",
    "%timeit data['INCIDENT_DATE_TIME'] = pd.to_datetime(data.INCIDENT_DATE_TIME, infer_datetime_format=True)\n",
    "%timeit data['ARRIVAL_DATE_TIME'] = pd.to_datetime(data.ARRIVAL_DATE_TIME, infer_datetime_format=True)\n",
    "%timeit data['LAST_UNIT_CLEARED_DATE_TIME'] = pd.to_datetime(data.LAST_UNIT_CLEARED_DATE_TIME, \n",
    "                                                             infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Looks like we have cleaned up our data now. Let's visualize it first and then save it into a .csv that I can import later and start working from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"clean_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can start from here later. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data_mod = pd.read_csv(\"clean_data.csv\", low_memory=False)\n",
    "#                        , parse_dates=['INCIDENT_DATE_TIME ', 'ARRIVAL_DATE_TIME', 'LAST_UNIT_CLEARED_DATE_TIME']\n",
    "#                        , infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_mod.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Datetime data\n",
    "\n",
    "%timeit data['INCIDENT_DATE_TIME'] = pd.to_datetime(data.INCIDENT_DATE_TIME, infer_datetime_format=True)\n",
    "%timeit data['ARRIVAL_DATE_TIME'] = pd.to_datetime(data.ARRIVAL_DATE_TIME, infer_datetime_format=True)\n",
    "%timeit data['LAST_UNIT_CLEARED_DATE_TIME'] = pd.to_datetime(data.LAST_UNIT_CLEARED_DATE_TIME, infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What proportion of FDNY responses in this dataset correspond to the most common type of incident?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['INCIDENT_TYPE_DESC'].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_incident = (data['INCIDENT_TYPE_DESC'] == 412).sum()\n",
    "most_freq_incident"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look like the most common incident is No. 412, happening 102410 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_row, count_column = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of data points. \n",
    "\n",
    "count_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proportion of most common incident\n",
    "\n",
    "prop_1 = most_freq_incident/count_row\n",
    "prop_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is the ratio of the average number of units that arrive to a scene of an incident classified as '111 - Building fire' to the number that arrive for '651 - Smoke scare, odor of smoke'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel1 = data.loc[(data['INCIDENT_TYPE_DESC'] == 111)]\n",
    "sel1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel2 = data.loc[(data['INCIDENT_TYPE_DESC'] == 651)]\n",
    "sel2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_111 = sel1['UNITS_ONSCENE'].mean()\n",
    "mean_651 = sel2['UNITS_ONSCENE'].mean()\n",
    "\n",
    "prop_2 = mean_111/mean_651\n",
    "prop_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How many times more likely is an incident in Staten Island a false call compared to in Manhattan? The answer should be the ratio of Staten Island false call rate to Manhattan false call rate. A false call is an incident for which 'INCIDENT_TYPE_DESC' is '710 - Malicious, mischievous false call, other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel3 = data.loc[(data['INCIDENT_TYPE_DESC'] == 710)]\n",
    "sel3.head()\n",
    "sel3.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we don't have many false calls anyway. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was some information lost in converting the last row (BOROUGH_DESC) to just numbers. I add context here: \n",
    "\n",
    "1. Manhattan\n",
    "2. Bronx\n",
    "3. Staten Island\n",
    "4. Brooklyn\n",
    "5. Queens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_false_calls = (sel3['BOROUGH_DESC'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_false_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staten_island_false_calls = (sel3['BOROUGH_DESC'] == 3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staten_island_false_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_3= staten_island_false_calls/manhattan_false_calls\n",
    "prop_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Check the distribution of the number of minutes it takes between the time a '111 - Building fire' incident has been logged into the Computer Aided Dispatch system and the time at which the first unit arrives on scene. What is the third quartile of that distribution. Note: the number of minutes can be fractional (ie, do not round)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel1.head()\n",
    "pd.options.mode.chained_assignment = None #Reomve the flag for appending a new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel1['ARRIVAL_TIME'] = sel1['ARRIVAL_DATE_TIME'] - sel1['INCIDENT_DATE_TIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting this to numerical minutes. \n",
    "\n",
    "sel1['ARRIVAL_TIME_IN_MINS'] = sel1['ARRIVAL_TIME'].dt.total_seconds().div(60).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the distribution\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sel1['ARRIVAL_TIME_IN_MINS'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The third quartile can be found using the \"decribe\" function, \n",
    "\n",
    "sel1['ARRIVAL_TIME_IN_MINS'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or, using, \n",
    "\n",
    "prop_4 = sel1['ARRIVAL_TIME_IN_MINS'].quantile(0.75)\n",
    "prop_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the answers match anyway. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. We can use the FDNY dataset to investigate at what time of the day people cook most. Compute what proportion of all incidents are cooking fires for every hour of the day by normalizing the number of cooking fires in a given hour by the total number of incidents that occured in that hour. Find the hour of the day that has the highest proportion of cooking fires and submit that proportion of cooking fires. A cooking fire is an incident for which 'INCIDENT_TYPE_DESC' is '113 - Cooking fire, confined to container'. Note: round incident times down. For example, if an incident occured at 22:55 it occured in hour 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['INCIDENT_DATE_TIME'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the rounded off hour\n",
    "\n",
    "data['INCIDENT_HOUR'] = data['INCIDENT_DATE_TIME'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count incidents per hour\n",
    "\n",
    "incidents_per_hour = data['INCIDENT_HOUR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_per_hour_sorted = incidents_per_hour.sort_index()\n",
    "incidents_per_hour_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`incidents_per_hour_sorted` gives the number of incidents every hour. Let's narrow down our data to Cooking incidents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel4 = data.loc[(data['INCIDENT_TYPE_DESC'] == 113)]\n",
    "sel4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing the same analysis as above for cooking incidents, \n",
    "\n",
    "cooking_incidents_per_hour = sel4['INCIDENT_HOUR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooking_incidents_per_hour_sorted = cooking_incidents_per_hour.sort_index()\n",
    "cooking_incidents_per_hour_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_of_cooking_incidents = cooking_incidents_per_hour_sorted/incidents_per_hour_sorted\n",
    "prop_5 = max(ratio_of_cooking_incidents)\n",
    "prop_idx = ratio_of_cooking_incidents.idxmax()\n",
    "print(prop_5,prop_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What is the coefficient of determination (R squared) between the number of residents at each zip code and the number of inicidents whose type is classified as '111 - Building fire' at each of those zip codes. Note: The 2010 US Census population by zip code dataset should be downloaded from [here](https://s3.amazonaws.com/SplitwiseBlogJB/2010+Census+Population+By+Zipcode+(ZCTA).csv). You will need to use both the FDNY responses and the US Census dataset. Ignore zip codes that do not appear in the census table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pd.read_csv(\"2010+Census+Population+By+Zipcode+(ZCTA).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = census_data.rename(index=str, columns={\"Zip Code ZCTA\": \"ZIP_CODE\", \"2010 Census Population\": \"POPULATION\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload fire incidents\n",
    "\n",
    "sel1 = data.loc[(data['INCIDENT_TYPE_DESC'] == 111)]\n",
    "sel1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping data by zip code\n",
    "\n",
    "zip_codes = sel1['ZIP_CODE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_codes = zip_codes.rename_axis('ZIP_CODE').reset_index(name='NUMBER_OF_FIRE_INCIDENTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping indices where Zip Code is 9999: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_zip_99999 = zip_codes[zip_codes.ZIP_CODE == 99999].index\n",
    "zip_codes = zip_codes.drop(index_zip_99999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = zip_codes.merge(census_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phew, now let's find out the Co-efficient of Determination (R^2)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "prop_6 = r2_score(joined_df['POPULATION'], joined_df['NUMBER_OF_FIRE_INCIDENTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. For this question, only consider incidents that have information about whether a CO detector was present or not. We are interested in how many times more likely it is that an incident is long when no CO detector is present compared to when a CO detector is present. For events with CO detector and for those without one, compute the proportion of incidents that lasted 20-30, 30-40, 40-50, 50-60, and 60-70 minutes (both interval boundary values included) by dividing the number of incidents in each time interval with the total number of incidents. For each bin, compute the ratio of the 'CO detector absent' frequency to the 'CO detector present' frequency. Perform a linear regression of this ratio to the mid-point of the bins. From this, what is the predicted ratio for events lasting 39 minutes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel5 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows where we don't have information whether a CO detector was present or not. \n",
    "\n",
    "sel5 = sel5.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TOTAL_INCIDENT_DURATION` is in seconds. Converting to minutes first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel5['TOTAL_INCIDENT_DURATION'] = sel5['TOTAL_INCIDENT_DURATION']/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_total_incidents = pd.cut(sel5['TOTAL_INCIDENT_DURATION'], [20.0, 30.0, 40.0, 50.0, 60.0, 70.0])\n",
    "total_incidents = bin_total_incidents.value_counts()\n",
    "total_incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel6 = sel5.loc[(data['CO_DETECTOR_PRESENT_DESC'] == 'Yes')]\n",
    "sel6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel7 = sel5.loc[(data['CO_DETECTOR_PRESENT_DESC'] == 'No')]\n",
    "sel7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_yes = pd.cut(sel6['TOTAL_INCIDENT_DURATION'], [20.0, 30.0, 40.0, 50.0, 60.0, 70.0])\n",
    "co_detector_present = bins_yes.value_counts()\n",
    "co_detector_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_no = pd.cut(sel7['TOTAL_INCIDENT_DURATION'], [20.0, 30.0, 40.0, 50.0, 60.0, 70.0])\n",
    "co_detector_absent = bins_no.value_counts()\n",
    "co_detector_absent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, need to normalise and then compute proprtion of events in the Yes and No bin out of the total incidents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_yes = co_detector_present/total_incidents\n",
    "normalised_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_no = co_detector_absent/total_incidents\n",
    "normalised_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_ratio_of_co = normalised_yes/normalised_no\n",
    "normalised_ratio_of_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_ratio_of_co = normalised_ratio_of_co.rename_axis('BINS').reset_index(name='RATIO_OF_INCIDENTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_ratio_of_co.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_ratio_of_co.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us perform the Linear Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_yes.plot.scatter(x = \"\" ,y = \"TOTAL_INCIDENT_DURATION\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(normalised_ratio_of_co)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
